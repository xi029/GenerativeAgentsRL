import requests
import argparse
import json
import os
import re
from typing import Dict, List, Optional
from openai import OpenAI

# ===================== é…ç½®é¡¹ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰ =====================
DEFAULT_API_KEY = os.environ.get('DEEPSEEK_API_KEY') or "sk-e1fecac7367d455582948fdbc52cc4e4" # ä½ çš„DeepSeek API Key
DEFAULT_BASE_URL = "https://api.deepseek.com"  # DeepSeek API åœ°å€
DEFAULT_MODEL = "deepseek-chat"  # DeepSeek æ¨¡å‹

# è¯„ä¼°ç»´åº¦
EVAL_DIMENSIONS = [
    "ä»»åŠ¡å®Œæˆåº¦", 
    "åä½œæ•ˆç‡", 
    "è¡Œä¸ºä¸€è‡´æ€§", 
    "é€»è¾‘è¿è´¯æ€§"
]

# ===================== æ ¸å¿ƒå‡½æ•° =====================
def load_simulation_log(log_path: str) -> str:
    """åŠ è½½simulation.mdæ—¥å¿—æ–‡ä»¶"""
    if not os.path.exists(log_path):
        print(f"Error: æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_path}")
        return ""
    try:
        with open(log_path, "r", encoding="utf-8") as f:
            content = f.read()
            # ç®€å•è¿‡æ»¤ï¼Œåªä¿ç•™ä¸»è¦å†…å®¹ï¼Œé¿å…Tokenè¿‡é•¿
            # å‡è®¾simulation.mdä¸»è¦åŒ…å«æ—¶é—´çº¿å’ŒAgentè¡Œä¸º
            return content
    except Exception as e:
        print(f"åŠ è½½æ—¥å¿—å¤±è´¥ï¼š{e}")
        return ""

def build_eval_prompt(log_content: str, dimensions: List[str]) -> str:
    """æ„é€ å¤§æ¨¡å‹æ‰“åˆ†çš„Prompt"""
    # æˆªå–æ—¥å¿—ä»¥é€‚åº”ä¸Šä¸‹æ–‡çª—å£ï¼Œä¼˜å…ˆä¿ç•™æœ€è¿‘çš„äº¤äº’æˆ–å‡åŒ€é‡‡æ ·
    # è¿™é‡Œç®€å•æˆªå–å‰ 12000 ä¸ªå­—ç¬¦ (çº¦ 3-4k token)
    truncated_log = log_content[:12000]
    if len(log_content) > 12000:
        truncated_log += "\n...(æ—¥å¿—æˆªæ–­)..."

    prompt = f"""
ä½ æ˜¯ä¸€ä½å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-Agent Systemï¼‰çš„ä¸“å®¶è¯„ä¼°å‘˜ã€‚è¯·æ ¹æ®æä¾›çš„ä»¿çœŸæ—¥å¿—ç‰‡æ®µï¼Œå¯¹æ™ºèƒ½ä½“çš„è¡¨ç°è¿›è¡Œé‡åŒ–è¯„ä¼°ã€‚

### ä»¿çœŸæ—¥å¿—ç‰‡æ®µ
{truncated_log}

### è¯„ä¼°ä»»åŠ¡
è¯·å¯¹ä¸Šè¿°ä»¿çœŸè¿‡ç¨‹è¿›è¡Œæ‰“åˆ†ï¼Œè¯„åˆ†èŒƒå›´ 0-10 åˆ†ï¼ˆä¿ç•™1ä½å°æ•°ï¼‰ã€‚

### è¯„ä¼°ç»´åº¦
1. **ä»»åŠ¡å®Œæˆåº¦**ï¼šAgent æ˜¯å¦æœ‰æ•ˆåœ°æ¨è¿›äº†å…¶æ—¢å®šç›®æ ‡ï¼ˆå¦‚å†™ä½œã€ç ”ç©¶ã€ç¤¾äº¤ç­‰ï¼‰ï¼Ÿ
2. **åä½œæ•ˆç‡**ï¼šAgent ä¹‹é—´çš„äº¤äº’ï¼ˆå¯¹è¯ã€ç­‰å¾…ï¼‰æ˜¯å¦æœ‰æ•ˆä¿ƒè¿›äº†ä¿¡æ¯å…±äº«æˆ–ä»»åŠ¡åä½œï¼Ÿæ˜¯å¦å­˜åœ¨æ— æ•ˆçš„å¤è¯»æˆ–æ­»å¾ªç¯ï¼Ÿ
3. **è¡Œä¸ºä¸€è‡´æ€§**ï¼šAgent çš„è¡Œä¸ºæ˜¯å¦ç¬¦åˆå…¶äººè®¾ï¼ˆå¦‚èŒä¸šã€æ€§æ ¼ï¼‰ä»¥åŠæ—¶é—´/ç©ºé—´é€»è¾‘ï¼Ÿ
4. **é€»è¾‘è¿è´¯æ€§**ï¼šAgent çš„è¡Œä¸ºåºåˆ—ï¼ˆæ€è€ƒ->è®¡åˆ’->è¡ŒåŠ¨ï¼‰æ˜¯å¦é€»è¾‘è‡ªæ´½ï¼Ÿ

### è¾“å‡ºæ ¼å¼
è¯·ä»…è¾“å‡ºä¸€ä¸ªåˆæ³•çš„ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å« markdown æ ¼å¼æ ‡è®°æˆ–å…¶ä»–åºŸè¯ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
{{
    "ä»»åŠ¡å®Œæˆåº¦": 0.0,
    "åä½œæ•ˆç‡": 0.0,
    "è¡Œä¸ºä¸€è‡´æ€§": 0.0,
    "é€»è¾‘è¿è´¯æ€§": 0.0,
    "ç®€è¯„": "ä¸€å¥è¯è¯„ä»·"
}}
"""
    return prompt.strip()

def call_llm_api(prompt: str, model: str, base_url: str, api_key: str) -> Dict:
    """è°ƒç”¨ LLM API è·å–æ‰“åˆ†ç»“æœ"""
    
    try:
        print(f"æ­£åœ¨è¯·æ±‚æ¨¡å‹ {model} è¿›è¡Œè¯„ä¼°...")
        
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful assistant"},
                {"role": "user", "content": prompt},
            ],
            stream=False,
            temperature=0.1, # ä½æ¸©åº¦ä»¥ä¿è¯è¯„ä¼°å®¢è§‚æ€§
            max_tokens=500
        )
        
        content = response.choices[0].message.content.strip()
        
        # å°è¯•æå– JSON
        # ç§»é™¤å¯èƒ½çš„ <think> æ ‡ç­¾ (é’ˆå¯¹ DeepSeek-R1 ç­‰)
        content = re.sub(r"<think>.*?</think>", "", content, flags=re.DOTALL).strip()
        
        # æå– JSON å—
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            return json.loads(json_str)
        else:
            print(f"æ— æ³•è§£æ JSON: {content}")
            return {}
            
    except Exception as e:
        print(f"APIè°ƒç”¨å¤±è´¥ï¼š{e}")
        return {}


def generate_eval_report(
    log_path: str, 
    label: str,
    model: str,
    base_url: str,
    api_key: str
) -> Dict:
    """ç”Ÿæˆå•ä»½æ—¥å¿—çš„è¯„ä¼°æŠ¥å‘Š"""
    print(f"\n===== å¼€å§‹è¯„ä¼°: {label} =====")
    log_content = load_simulation_log(log_path)
    if not log_content:
        return {}
    
    prompt = build_eval_prompt(log_content, EVAL_DIMENSIONS)
    score_dict = call_llm_api(prompt, model, base_url, api_key)
    
    if not score_dict:
        print("è¯„ä¼°å¤±è´¥ï¼Œæœªè·å–åˆ°æœ‰æ•ˆåˆ†æ•°ã€‚")
        return {dim: 0.0 for dim in EVAL_DIMENSIONS}

    # è¡¥å…¨å¯èƒ½ç¼ºå¤±çš„å­—æ®µ
    for dim in EVAL_DIMENSIONS:
        if dim not in score_dict:
            score_dict[dim] = 0.0
            
    # è®¡ç®—æ€»åˆ†
    valid_scores = [score_dict[d] for d in EVAL_DIMENSIONS]
    score_dict["æ€»åˆ†"] = round(sum(valid_scores) / len(valid_scores), 1)
    
    print(f"[{label}] è¯„ä¼°ç»“æœï¼š")
    for k, v in score_dict.items():
        print(f"  {k}: {v}")
        
    return score_dict

def main():
    parser = argparse.ArgumentParser(description="è¯„ä¼° Generative Agents ä»¿çœŸç»“æœ")
    parser.add_argument("--before", help="ä¼˜åŒ–å‰ï¼ˆBaselineï¼‰çš„ simulation.md è·¯å¾„")
    parser.add_argument("--after", required=True, help="ä¼˜åŒ–åï¼ˆRLï¼‰çš„ simulation.md è·¯å¾„")
    parser.add_argument("--model", default=DEFAULT_MODEL, help="è¯„ä¼°ä½¿ç”¨çš„æ¨¡å‹åç§°")
    parser.add_argument("--base_url", default=DEFAULT_BASE_URL, help="API Base URL")
    parser.add_argument("--api_key", default=DEFAULT_API_KEY, help="API Key")
    
    args = parser.parse_args()

    scores_before = {}
    if args.before:
        scores_before = generate_eval_report(args.before, "ä¼˜åŒ–å‰(Baseline)", args.model, args.base_url, args.api_key)
    
    scores_after = generate_eval_report(args.after, "ä¼˜åŒ–å(RL)", args.model, args.base_url, args.api_key)

    if scores_before and scores_after:
        print("\n===== âš”ï¸ å¯¹æ¯”è¯„ä¼°æŠ¥å‘Š âš”ï¸ =====")
        print(f"{'ç»´åº¦':<10} | {'ä¼˜åŒ–å‰':<8} | {'ä¼˜åŒ–å':<8} | {'å˜åŒ–':<8}")
        print("-" * 46)
        
        all_dims = EVAL_DIMENSIONS + ["æ€»åˆ†"]
        for dim in all_dims:
            s1 = scores_before.get(dim, 0.0)
            s2 = scores_after.get(dim, 0.0)
            diff = s2 - s1
            diff_str = f"{diff:+.1f}"
            if diff > 0:
                trend = "ğŸ”º"
            elif diff < 0:
                trend = "ğŸ”»"
            else:
                trend = "â–"
                
            print(f"{dim:<10} | {s1:<8} | {s2:<8} | {trend} {diff_str}")

if __name__ == "__main__":
    main()
